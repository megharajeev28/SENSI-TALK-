 **SensiTalk: Your Magical Communication Bridge**

**1. Project Overview:**
SensiTalk is an innovative AI-powered communication platform designed to bridge the profound gap for deaf, autistic, and non-verbal communities. It's our 'magic spell' for the unspoken, translating gestures and speech to ensure everyone has the fundamental right to be understood.

**2. Features:**
* **Available Now:**
    * **Gesture to Speech:** Real-time camera feed with simulated hand gesture recognition, converting text to speech using unique Harry Potter-themed character voices via the **Gemini API**.
    * **Speech to Text:** Offers live voice transcription, converting spoken words into text in real-time.
* **Core Concepts:** Real-time, two-way communication, with future focus on offline accessibility (for core AI models).
* **Future Magic:** Planned enhancements include advanced AI for accurate gesture recognition, customizable voice profiles, multi-language support, and smart device integration.

**3. Tech Stack:**
* **Frontend:** React, Tailwind CSS, Browser's Web Speech API, **Gemini API** (`gemini-2.5-flash-preview-tts`).
* **Backend (Placeholder):** Python Flask (for future advanced ML integration, API key management, data storage).

**4. Getting Started:**
Requires Node.js (for React) and Python (for Flask). Simply `npm install` and `npm start` for the frontend, and `pip install Flask Flask-Cors` then `python app.py` for the backend.

**5. Usage:**
Open the app (`http://localhost:3000`), grant camera/microphone permissions. Select "Gesture to Speech" to input or simulate gestures for HP voice output, or "Speech to Text" to transcribe live voice.

**6. Contributing:**
Contributions, bug fixes, and feature suggestions are warmly welcome!

**7. License:**
This project is licensed under the MIT License.

**8. Contact:**
For questions or support, please contact [Your Name/Email/GitHub Profile Link].

---
